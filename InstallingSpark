## For Mac Users 

Try Installing with Brew, this makes the life easy.
- Open your command line, if you have brew
      - update brew
  if you don't have brew,
      - Install brew, copy and paste the below command (Avialable at (http://brew.sh/))
      /usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
      
- Install Hadoop , spark uses yarn resources and this is essentials 
       -> brew install hadoop 
  sometimes this will through an error if your system doesn't have java, cool thing about brew is it provides a command to 
  install java, run that command and java gets installed.
  
- Install spark 
      -> brew install apache-spark 
      
Success: Spark got installed. 
run pyspark on command line and you should see the spark running 
